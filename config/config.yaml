
dataloader:
  data_dir: data
  batch_size: 2
  shuffle: True
  num_workers: 0
  #prefetch_factor: 2 # Should be >0 in case multiprocessing is enabled, i.e. num_workers > 0
  drop_last: False

model:
  embedding_dim: 768
  n_layers: 12
  heads: 12
  head_size: 64
  block_size: 64

trainer:
  step_per_epoch: 
  epochs: 100
  init_lr: 1e-3
  log_every_n_steps: 25
  device: mps